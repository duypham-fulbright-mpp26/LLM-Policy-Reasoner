# LLM-Policy-Reasoner

### Adaptive Large-Language-Model Framework for Policy Evaluation  
**Author:** Pham Binh Phuong Duy  
**Affiliation:** Master of Public Policy (MPP), Fulbright University Vietnam  
**Thesis Title:** *A Dual-Layer LLM Framework for Policymaking: Policy Evaluation and Public Response Simulation with a Case Study on Personal Income Tax In Vietnam*  
**Year:** 2025  

---

## ğŸ§© Overview

The **LLM-Policy-Reasoner** is a lightweight reasoning artefact developed as part of a Masterâ€™s thesis at Fulbright University Vietnam.  
It adapts the **LLM Economist** framework (Karten et al., 2025) for **policy evaluation** rather than optimisation.

Instead of simulating agents and maximising rewards, this artefact performs **structured reasoning** over fiscal policy trade-offs â€” particularly focusing on Vietnamâ€™s proposed **Personal Income Tax (PIT)** reform.  
The model evaluates each policy design across three normative dimensions:

1. **Efficiency** â€“ ability to raise revenue with minimal distortion  
2. **Equity** â€“ fairness and proportionality in burden distribution  
3. **Simplicity** â€“ administrative and compliance feasibility  

All evaluations are produced by a locally running LLM through **Ollama**, ensuring privacy, transparency, and reproducibility.

---

## âš™ï¸ Features

- Modular reasoning system using **Qwen 3 (8B)** via Ollama  
- Structured prompt architecture (system, context, criteria, user layers)  
- Multi-run evaluation (default 20 iterations per policy)  
- Automatic logging and reproducibility controls  
- Built-in retry and progress monitoring  
- Outputs both CSV and JSONL for analysis and audit trail  

---

## ğŸ§± Directory Structure

```
LLM-Policy-Reasoner/
â”‚
â”œâ”€â”€ policy_inputs/
â”‚   â””â”€â”€ pit_vn.json                # 7-bracket baseline + two 5-bracket options
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ policy_eval_system.txt     # LLM system role and output format
â”‚   â”œâ”€â”€ policy_eval_context_vn.txt # Vietnam PIT reform context (2025 draft)
â”‚   â”œâ”€â”€ policy_eval_criteria.txt   # Definitions of Efficiencyâ€“Equityâ€“Simplicity
â”‚   â””â”€â”€ policy_eval_user.txt       # Template for dynamic policy JSON input
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ policy_eval.py             # Main evaluation script
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ sample_result.csv          # Example run result
â”‚   â””â”€â”€ sample_audit.jsonl         # Full reasoning log (optional)
â”‚
â””â”€â”€ README.md
```

---

## ğŸ§° Installation

### 1. Clone and create environment
```bash
git clone https://github.com/duypham/LLM-Policy-Reasoner.git
cd LLM-Policy-Reasoner
conda create -n llmecon python=3.11 -y
conda activate llmecon
pip install requests tqdm pandas
```

### 2. Install and run Ollama
Download Ollama from [https://ollama.com/download](https://ollama.com/download).

Then pull and serve the model:
```bash
ollama pull qwen3:8b
ollama serve
```

The API should be accessible at:
```
http://localhost:11434/api/chat
```

---

## ğŸš€ Running the Model

### Windows (Anaconda Prompt)
```bat
set POLICY_MODEL=qwen3:8b
set POLICY_TEMP=0.3
set POLICY_SEED=42
set POLICY_NRUNS=20
set POLICY_TIMEOUT=600
python examples\policy_eval.py
```

### macOS / Linux
```bash
export POLICY_MODEL=qwen3:8b
export POLICY_TEMP=0.3
export POLICY_SEED=42
export POLICY_NRUNS=20
export POLICY_TIMEOUT=600
python examples/policy_eval.py
```

Progress will be displayed live.  
After completion, results are stored in:

```
outputs/policy_eval/policy_eval_YYYYMMDD_xxxxxx.csv
outputs/policy_eval/policy_eval_YYYYMMDD_xxxxxx.jsonl
```

---

## ğŸ“Š Output Files

| File | Description |
|------|--------------|
| `*.csv` | Structured summary with numeric scores (efficiency, equity, simplicity) and short rationales. |
| `*.jsonl` | Full raw outputs for traceability and validation. |
| `*.log` (optional) | Runtime logs showing retries and progress. |

Example CSV columns:

| policy | efficiency | equity | simplicity | r_efficiency | r_equity | r_simplicity | json_ok | iteration |
|--------|-------------|---------|-------------|---------------|-----------|---------------|----------|------------|

---

## ğŸ§  Model Configuration Rationale

| Parameter | Value | Justification |
|------------|--------|---------------|
| **Model** | Qwen 3 8B Instruct | Strong bilingual reasoning (Englishâ€“Vietnamese); runs locally without GPU clusters. |
| **Temperature** | 0.3 | Allows mild variation for nuanced reasoning while maintaining JSON consistency. |
| **Seed** | 42 | Ensures reproducibility across runs. |
| **N_RUNS** | 20 | Following Karten et al. (2025), stability is evaluated via multi-run mean/variance. |
| **Timeout** | 600 s | Ensures completion under CPU-only setups. |

---

## ğŸ” Verification & Validation Summary

- **Variance threshold:** ÏƒÂ² < 0.5 across 20 runs  
- **JSON validity:** > 95 % structured responses  
- **Ranking consistency:** identical relative order across runs  
- **Expert alignment:** deviation < 1 point per criterion in validation interviews  

---

## ğŸ“š Citation

If you reuse or reference this artefact, please cite:

> Pham Binh Phuong Duy (2025). *LLM-Policy-Reasoner: A Structured LLM Framework for Policy Evaluation in Vietnam*.  
> Masterâ€™s Thesis, Fulbright University Vietnam.  
> GitHub: [https://github.com/duypham/LLM-Policy-Reasoner](https://github.com/duypham/LLM-Policy-Reasoner)

---

## ğŸ“œ License

This repository is released under the **MIT License** for non-commercial academic use.  
Please acknowledge the author and institution in derived works.

---

## ğŸ§¾ Acknowledgements

This project draws conceptual inspiration from:
- **Karten et al. (2025). LLM Economist Framework** â€“ modular reasoning architecture.  
- **Zheng et al. (2022). AI Economist** â€“ multi-agent policy simulation.  
- **Moore (1995). Creating Public Value** â€“ legitimacy in public management.  

All implementation, adaptation, and evaluation design were independently developed by the author.
